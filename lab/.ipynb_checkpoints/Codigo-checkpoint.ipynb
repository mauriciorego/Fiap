{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto Final de Avaliação Substitutiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposta: “Avaliação de métodos de reconhecimento facial utilizando visão computacional”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'cv2.face'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import cv2.face\n",
    "\n",
    "cv2.face\n",
    "#<module 'cv2.face'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecção das faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_detection(image):\n",
    "    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    haar_classifier = cv2.CascadeClassifier('../Model/haarcascade_frontalface_default.xml')\n",
    "    face = haar_classifier.detectMultiScale(image_gray, scaleFactor=1.3, minNeighbors=1)\n",
    "    print( \"Faces\", face )\n",
    "    (x,y,w,h) = face[0]\n",
    "    return image_gray[y:y+w, x:x+h], face[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../dataset/training/1\n",
      "Faces [[ 164  278   69   69]\n",
      " [ 993 2220   24   24]\n",
      " [ 793 1344  436  436]\n",
      " [1205  899   53   53]\n",
      " [ 530 1294   53   53]]\n",
      "Faces [[751 482  59  59]\n",
      " [470 500  53  53]\n",
      " [575 494  67  67]\n",
      " [750 503  53  53]\n",
      " [287 469  61  61]\n",
      " [816 312  48  48]\n",
      " [692 311  50  50]\n",
      " [427 316  50  50]\n",
      " [566 317  48  48]\n",
      " [840 611  36  36]\n",
      " [496 349  53  53]]\n",
      "Faces [[ 633  481   31   31]\n",
      " [ 475  485   53   53]\n",
      " [ 584  480   63   63]\n",
      " [ 758  469   59   59]\n",
      " [1182  112   53   53]\n",
      " [ 820  295   48   48]\n",
      " [ 570  300   47   47]\n",
      " [ 432  303   44   44]\n",
      " [ 294  453   61   61]\n",
      " [ 466  443   79   79]]\n",
      "Faces [[ 408  262   50   50]\n",
      " [ 548  264   48   48]\n",
      " [ 795  265   52   52]\n",
      " [1164   77   53   53]\n",
      " [1069   88   53   53]\n",
      " [ 510  334  107  107]\n",
      " [ 255  420   62   62]\n",
      " [ 738  434   55   55]\n",
      " [ 559  447   63   63]]\n",
      "Faces [[1755 1096   53   53]\n",
      " [ 340  581  771  771]\n",
      " [1697 1170  151  151]\n",
      " [1761 2592   69   69]]\n",
      "Faces [[ 284  315  945  945]\n",
      " [1828 1786   53   53]\n",
      " [ 927 3047   53   53]\n",
      " [1238 1877   53   53]\n",
      " [1157 1852   69   69]\n",
      " [ 988 1925   89   89]\n",
      " [1546 2011   41   41]]\n",
      "Faces [[  44 3624   69   69]\n",
      " [1869 1956   31   31]]\n",
      "Faces [[58 23 62 62]]\n",
      "Faces [[57 23 64 64]]\n",
      "Faces [[ 96 178 268 268]]\n",
      "Faces [[618 639  89  89]]\n",
      "Faces [[ 85  90 322 322]\n",
      " [508 567  31  31]]\n",
      "Faces [[ 99 753 116 116]]\n",
      "Faces [[ 271 1034   53   53]\n",
      " [ 481 1066   89   89]]\n",
      "../dataset/training/2\n",
      "Faces [[568 557  69  69]\n",
      " [348 112 192 192]\n",
      " [537 672  53  53]]\n",
      "Faces [[243  51 106 106]]\n",
      "Faces [[447  88 188 188]\n",
      " [786 111 151 151]\n",
      " [278 626  69  69]]\n",
      "Faces [[400  82 158 158]\n",
      " [729 140  53  53]\n",
      " [815 138  53  53]\n",
      " [614 558 331 331]]\n",
      "Faces [[383 143 196 196]\n",
      " [256 534 116 116]]\n",
      "Faces [[676 580  69  69]\n",
      " [436 696  53  53]]\n",
      "Faces [[477  36  31  31]\n",
      " [683 162  24  24]\n",
      " [188 242 430 430]]\n",
      "Faces [[396  88 255 255]\n",
      " [258 411 196 196]\n",
      " [668 284  69  69]\n",
      " [626 657  64  64]\n",
      " [319 724  53  53]]\n",
      "Faces [[838 725  69  69]\n",
      " [850 753  57  57]\n",
      " [363 261 196 196]\n",
      " [844 819  53  53]\n",
      " [ 27 224 116 116]\n",
      " [322 734 196 196]]\n",
      "Faces [[200  81 147 147]]\n",
      "../dataset/training/3\n",
      "Faces [[134  96 559 559]]\n",
      "Faces [[129  48 180 180]\n",
      " [327 322  24  24]]\n",
      "Faces [[ 12 154 331 331]\n",
      " [373  68  47  47]\n",
      " [398 219 303 303]]\n",
      "Faces [[239 179 135 135]]\n",
      "Training Done\n",
      "Total faces =  28\n",
      "Total labels =  28\n"
     ]
    }
   ],
   "source": [
    "database = [\"Mauricio\", \"Marcio\", \"Alessandro\"]\n",
    "\n",
    "faces, labels = prepare_data('../dataset/training')\n",
    "\n",
    "print ('Total faces = ', len(faces))\n",
    "print ('Total labels = ', len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.face.EigenFaceRecognizer_create()\n",
    "\n",
    "model.train(faces, np.array(labels))\n",
    "\n",
    "def predict_image_eigen(test_image):\n",
    "    img = test_image.copy()\n",
    "    face, bounding_box = face_detection(test_image)\n",
    "    label = model.predict(face)\n",
    "    label_text = database[label-1]\n",
    "    print (label)\n",
    "    print (label_text)\n",
    "    (x,y,w,h) = bounding_box\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "    cv2.putText(img, label_text, (x,y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "    return img\n",
    "\n",
    "test1 = cv2.imread(\".//dataset//Test//Mauricio.png\")\n",
    "predict1 = predict_image_eigen(test1)\n",
    "cv2.imshow('Face Recognition', predict1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fisherfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.face.FisherFaceRecognizer_create()\n",
    "\n",
    "model.train(faces, np.array(labels))\n",
    "\n",
    "def prepare_data_fisher(data_path):\n",
    "    folders = os.listdir(data_path)\n",
    "    labels = []\n",
    "    faces = []\n",
    "    for folder in folders:\n",
    "        label = int(folder)\n",
    "        training_images_path = data_path + '/' + folder\n",
    "        \n",
    "        print( training_images_path )\n",
    "        \n",
    "        for image in os.listdir(training_images_path):\n",
    "            image_path = training_images_path + '/' + image\n",
    "            training_image = cv2.imread(image_path)\n",
    "            face, bounding_box = face_detection(training_image)\n",
    "            faces.append(face)\n",
    "            labels.append(label)        \n",
    "\n",
    "    print ('Training Done')\n",
    "    return faces, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Binary Patterns Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-9243fa0bbbd8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mtest1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".//dataset//Test//Mauricio.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mpredict1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_image_LBPH\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Face Recognition'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-9243fa0bbbd8>\u001b[0m in \u001b[0;36mpredict_image_LBPH\u001b[1;34m(test_image)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_image_LBPH\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mface\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbounding_box\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "model.train(faces, np.array(labels))\n",
    "\n",
    "def predict_image_LBPH(test_image):\n",
    "    img = test_image.copy()\n",
    "    face, bounding_box = face_detection(img)\n",
    "    label = model.predict(face)\n",
    "    label_text = database[label-1]\n",
    "    print (label)\n",
    "    print (label_text)\n",
    "    (x,y,w,h) = bounding_box\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "    cv2.putText(img, label_text, (x,y), cv2.FONT_HERSHEY_PLAIN, 1.5, (0, 255, 0), 2)\n",
    "    return img\n",
    "\n",
    "test1 = cv2.imread(\".//dataset//Test//Mauricio.png\")\n",
    "predict1 = predict_image_LBPH(test1)\n",
    "cv2.imshow('Face Recognition', predict1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
